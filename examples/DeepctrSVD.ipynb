{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepCTR's SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD is matrix factorization algorithm popularly used in recommedation system applications such as movie & product recommendation.\n",
    "\n",
    "This factorization technique is available for training & testing on recommendation datasets through libraries such as surpriselib which analytically does the factorization & produces decomposed matrices.\n",
    "Whereas DeepCTR packages several FM techniques implemented through their DNN equivalents. Here one DeepCTR's method DeepFM is utilised to realise the implementation equivalence of SVD; Since the SVD results are here obtained through underlying Deep Neural Net, therefore DeepCTR's SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following notebook serves as Usage guide**\n",
    "_______________________________________________\n",
    "* The SVD module requires passing feature_column value (which are nothing but `SparseFeat` instances for each input sparse feature) to obtain a tensorflow model.\n",
    "* Towards the end, the obatained model is evaluating against sample test values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load sample dataset as pandas dataframe\n",
    "___________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* List `sparse_features` & label encode input dataframe.\n",
    "* Perform `train_test_split` to output training/test data and labels for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:root:\n",
      "DeepCTR version 0.7.0 detected. Your version is 0.6.3.\n",
      "Use `pip install -U deepctr` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR/releases/tag/v0.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.inputs import SparseFeat\n",
    "\n",
    "\n",
    "data_path = os.path.expanduser('u.data')\n",
    "df= pd.read_csv(data_path, sep='\\t',names= 'user_id,movie_id,rating,timestamp'.split(','))#, header=None)#used for DeepCTR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* List **sparse features** from input dataframe\n",
    "________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names: ['user_id', 'movie_id'] \n",
      "label name: ['rating']\n"
     ]
    }
   ],
   "source": [
    "sparse_features = [\"user_id\", \"movie_id\"]\n",
    "y= ['rating']\n",
    "print('feature names:',sparse_features, '\\nlabel name:',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Label encoding features of input dataframe\n",
    " __________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0      195       241       3  881250949\n",
       "1      185       301       3  891717742\n",
       "2       21       376       1  878887116"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        df[feat] = lbe.fit_transform(df[feat])\n",
    "        \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing training input data & target labels.**\n",
    "_____________________________________________\n",
    "* Training & test input data should be a list of numpy arrays of `user_ids` & `movie_ids`.\n",
    "* Labels as numpy array of target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_model_input = [train[name].values for name in sparse_features]#includes values from only data[user_id], data[movie_id]\n",
    "train_lbl = train[y].values\n",
    "\n",
    "test_model_input = [test[name].values for name in sparse_features]\n",
    "test_lbl = test[y].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:\n",
      " [array([415, 605, 739, ..., 845, 325, 515]), array([400, 759, 327, ..., 191, 674, 285])] \n",
      "\n",
      "training labels:\n",
      " [[2]\n",
      " [3]\n",
      " [3]\n",
      " ...\n",
      " [5]\n",
      " [4]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "print('training data:\\n', train_model_input, '\\n\\ntraining labels:\\n', train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Obtain feature columns\n",
    "________________________________________________\n",
    "* Perform required data preparatory operations as described in DeepCtr docs (refer https://deepctr-doc.readthedocs.io/en/latest/Quick-Start.html).\n",
    "\n",
    "* Defining **feature columns** as list of SparseFeat instances for each sparse feature, here -- `user_id`, `movie_id`, by passing in `feature_name`, `num_unique feature vals` as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat:user_id, SparseFeat:movie_id]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [SparseFeat(feat, df[feat].nunique()) for feat in sparse_features]\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Import `SVD` from `mlsquare.layers.deepctr`\n",
    "____________________________________________\n",
    "* Instantiate the model.\n",
    "* Train the model & evaluate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-12-06 03:02:27,487\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-12-06_03-02-27_10871/logs.\n",
      "2019-12-06 03:02:27,598\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:44590 to respond...\n",
      "2019-12-06 03:02:27,737\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:20042 to respond...\n",
      "2019-12-06 03:02:27,746\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-12-06 03:02:27,793\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    }
   ],
   "source": [
    "from mlsquare.layers.deepctr import SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now Instantiate the model by passing in args-- `feature_columns` & `embedding_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/deepctr/layers/utils.py:156: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/deepctr/layers/utils.py:156: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_id (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_user_id (Embedding)  (None, 1, 100)       94300       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_movie_id (Embedding) (None, 1, 100)       168200      movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "no_mask (NoMask)                (None, 1, 100)       0           sparse_emb_user_id[0][0]         \n",
      "                                                                 sparse_emb_movie_id[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2, 100)       0           no_mask[0][0]                    \n",
      "                                                                 no_mask[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fm (FM)                         (None, 1)            0           concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 262,500\n",
      "Trainable params: 262,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SVD(feature_columns, embedding_size=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compile the model & fit on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64000 samples, validate on 16000 samples\n",
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 3s - loss: 6.1732 - mean_squared_error: 6.1471 - val_loss: 1.5249 - val_mean_squared_error: 1.4720\n",
      "Epoch 2/8\n",
      " - 3s - loss: 1.1949 - mean_squared_error: 1.1329 - val_loss: 1.1028 - val_mean_squared_error: 1.0346\n",
      "Epoch 3/8\n",
      " - 3s - loss: 1.0318 - mean_squared_error: 0.9602 - val_loss: 1.0583 - val_mean_squared_error: 0.9840\n",
      "Epoch 4/8\n",
      " - 3s - loss: 1.0028 - mean_squared_error: 0.9270 - val_loss: 1.0338 - val_mean_squared_error: 0.9565\n",
      "Epoch 5/8\n",
      " - 3s - loss: 0.9831 - mean_squared_error: 0.9048 - val_loss: 1.0326 - val_mean_squared_error: 0.9534\n",
      "Epoch 6/8\n",
      " - 3s - loss: 0.9621 - mean_squared_error: 0.8818 - val_loss: 1.0174 - val_mean_squared_error: 0.9364\n",
      "Epoch 7/8\n",
      " - 3s - loss: 0.9319 - mean_squared_error: 0.8499 - val_loss: 1.0030 - val_mean_squared_error: 0.9197\n",
      "Epoch 8/8\n",
      " - 3s - loss: 0.8938 - mean_squared_error: 0.8097 - val_loss: 0.9979 - val_mean_squared_error: 0.9128\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", \"mse\", metrics=['mse'] )\n",
    "history = model.fit(train_model_input, train_lbl, batch_size=64, epochs=8, verbose=2, validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluating model prediction on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test user id: 822 & item id : 650 \n",
      "True rating: [5] \n",
      "Model prediction is: [4.842552]\n"
     ]
    }
   ],
   "source": [
    "user_id = test_model_input[0][1]\n",
    "item_id = test_model_input[1][1]\n",
    "true_y= test[y].values[1]\n",
    "print('For test user id: {} & item id : {} \\nTrue rating: {} \\nModel prediction is: {}'.format(user_id, item_id, true_y, model.predict(test_model_input)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
